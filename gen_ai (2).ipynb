{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!apt-get install git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_bntcj78Agi5",
        "outputId": "d5ffb825-6972-40a1-feb0-e34798045545"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "git is already the newest version (1:2.34.1-1ubuntu1.12).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 34 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/parthmodi444/AI-AGENT.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eT7MJGc3BFND",
        "outputId": "eff86fb0-70b8-4dea-b7c2-68d5dfbecc83"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'AI-AGENT'...\n",
            "warning: You appear to have cloned an empty repository.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git init\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ksshec7fBjy7",
        "outputId": "ef0d2c0d-e782-4f2c-fdcf-0fe3423e65ad"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mhint: Using 'master' as the name for the initial branch. This default branch name\u001b[m\n",
            "\u001b[33mhint: is subject to change. To configure the initial branch name to use in all\u001b[m\n",
            "\u001b[33mhint: of your new repositories, which will suppress this warning, call:\u001b[m\n",
            "\u001b[33mhint: \u001b[m\n",
            "\u001b[33mhint: \tgit config --global init.defaultBranch <name>\u001b[m\n",
            "\u001b[33mhint: \u001b[m\n",
            "\u001b[33mhint: Names commonly chosen instead of 'master' are 'main', 'trunk' and\u001b[m\n",
            "\u001b[33mhint: 'development'. The just-created branch can be renamed via this command:\u001b[m\n",
            "\u001b[33mhint: \u001b[m\n",
            "\u001b[33mhint: \tgit branch -m <name>\u001b[m\n",
            "Initialized empty Git repository in /content/.git/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hCq-Gd1fBlcW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git config --global user.email \"modi.parth18@siesgst.ac.in\"\n",
        "!git config --global user.name \"parthmodi444\""
      ],
      "metadata": {
        "id": "G_fNLfQkBtu0"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git add gen_ai.ipynb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HFrp6v4sCgsD",
        "outputId": "64a2f1c5-7fd8-43fd-921e-2a4e69973c1b"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: pathspec 'gen_ai.ipynb' did not match any files\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git add .\n",
        "!git commit -m \"first commit\"\n",
        "!git push"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hdFcUNkcBQRM",
        "outputId": "d4ee6ca3-16d7-481b-b246-1cc86cf9a668"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "error: 'AI-AGENT/' does not have a commit checked out\n",
            "fatal: adding files failed\n",
            "On branch master\n",
            "\n",
            "Initial commit\n",
            "\n",
            "Untracked files:\n",
            "  (use \"git add <file>...\" to include in what will be committed)\n",
            "\t\u001b[31m.config/\u001b[m\n",
            "\t\u001b[31mAI-AGENT/\u001b[m\n",
            "\t\u001b[31mdrive/\u001b[m\n",
            "\t\u001b[31msample_data/\u001b[m\n",
            "\n",
            "nothing added to commit but untracked files present (use \"git add\" to track)\n",
            "fatal: No configured push destination.\n",
            "Either specify the URL from the command-line or configure a remote repository using\n",
            "\n",
            "    git remote add <name> <url>\n",
            "\n",
            "and then push using the remote name\n",
            "\n",
            "    git push <name>\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5gjFQTUiE2GW",
        "outputId": "441ec6c9-bce1-495f-b9f5-8b456253662c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.75.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.13.2)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.11/dist-packages (1.1.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.9.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.11.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.13.2)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.8)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install openai pandas matplotlib seaborn nltk requests python-dotenv\n",
        "\n",
        "import os\n",
        "import json\n",
        "import time\n",
        "import requests\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime, timedelta\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "from google.colab import userdata\n",
        "import nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KI383_5oE6gh",
        "outputId": "77e9ed3f-99c1-48ce-ceea-80b0d7ef3a6b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "nltk.download('vader_lexicon')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "CjMAMysLE9Jd"
      },
      "outputs": [],
      "source": [
        "OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n",
        "NEWS_API_KEY = userdata.get('NEWS_API_KEY')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "4FeKG2JlE_3l"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "# Initialize OpenAI client\n",
        "client = OpenAI(api_key=OPENAI_API_KEY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Cz33QLzFE0D",
        "outputId": "b76ce070-4ac4-42e1-8e20-d35960a3a4ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Set up paths for RAG documents\n",
        "RAG_FOLDER = \"/content/drive/MyDrive/news_aggregator_rag\"\n",
        "os.makedirs(RAG_FOLDER, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "E66CbCiUFIWm"
      },
      "outputs": [],
      "source": [
        "news_analysis_guidelines = \"\"\"# News Analysis Methodology\n",
        "\n",
        "## Principles of News Analysis\n",
        "1. **Verify sources**: Always check the credibility of sources\n",
        "2. **Cross-reference information**: Confirm facts across multiple outlets\n",
        "3. **Identify bias**: Recognize potential biases in reporting\n",
        "4. **Contextual understanding**: Place news in historical and cultural context\n",
        "5. **Separate fact from opinion**: Distinguish between factual reporting and commentary\n",
        "\n",
        "## Key Analytical Frameworks\n",
        "1. **5W1H Analysis**: Who, What, When, Where, Why, and How\n",
        "2. **SWOT Analysis**: Strengths, Weaknesses, Opportunities, and Threats\n",
        "3. **Stakeholder Analysis**: Identify who is affected and how\n",
        "4. **Trend Analysis**: How does this fit into longer-term patterns?\n",
        "5. **Comparative Analysis**: How does coverage differ across sources?\n",
        "\n",
        "## Best Practices for News Summarization\n",
        "1. Prioritize key information over secondary details\n",
        "2. Maintain objectivity in presentation\n",
        "3. Include diverse perspectives when available\n",
        "4. Acknowledge limitations in available information\n",
        "5. Update analysis when new information emerges\n",
        "\n",
        "## Sentiment Analysis in News\n",
        "1. **Positive sentiment**: Language expressing approval, optimism, progress\n",
        "2. **Negative sentiment**: Language expressing criticism, pessimism, decline\n",
        "3. **Neutral sentiment**: Factual reporting without evaluative language\n",
        "4. Recognize that sentiment can vary by topic, source, and audience\n",
        "\n",
        "## Types of News Bias\n",
        "1. **Selection bias**: What stories are covered or ignored\n",
        "2. **Placement bias**: Where stories appear and how much prominence they receive\n",
        "3. **Source bias**: Which voices and perspectives are included\n",
        "4. **Tone bias**: Language choices that subtly influence perception\n",
        "5. **Visual bias**: How images frame the narrative\n",
        "\n",
        "## Ethical Considerations\n",
        "1. Respect privacy and dignity of individuals\n",
        "2. Consider consequences of amplifying certain stories\n",
        "3. Avoid sensationalism and fearmongering\n",
        "4. Provide context for potentially misleading statistics\n",
        "5. Acknowledge unknowns and uncertainties\n",
        "\"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "_YvtkP_pGVvL"
      },
      "outputs": [],
      "source": [
        "with open(f\"{RAG_FOLDER}/news_analysis_guidelines.md\", \"w\") as f:\n",
        "    f.write(news_analysis_guidelines)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "vOWqTkFpH86z"
      },
      "outputs": [],
      "source": [
        "news_sources_info = \"\"\"# Major News Sources Information\n",
        "\n",
        "## News Source Profiles\n",
        "\n",
        "### Reuters\n",
        "**Political Leaning**: Generally Neutral\n",
        "**Focus Areas**: Global news, financial markets, business\n",
        "**Notable For**: Factual reporting with minimal bias\n",
        "**Founding Year**: 1851\n",
        "**Headquarters**: London, UK\n",
        "\n",
        "### Associated Press (AP)\n",
        "**Political Leaning**: Generally Neutral\n",
        "**Focus Areas**: Breaking news, national and international coverage\n",
        "**Notable For**: Widely syndicated content, factual reporting\n",
        "**Founding Year**: 1846\n",
        "**Headquarters**: New York City, USA\n",
        "\n",
        "### BBC\n",
        "**Political Leaning**: Slightly left of center\n",
        "**Focus Areas**: Global news, UK news, cultural reporting\n",
        "**Notable For**: Public broadcasting, international perspective\n",
        "**Founding Year**: 1922\n",
        "**Headquarters**: London, UK\n",
        "\n",
        "### Fox News\n",
        "**Political Leaning**: Right-leaning\n",
        "**Focus Areas**: US politics, conservative viewpoints\n",
        "**Notable For**: Opinion-based shows, conservative commentary\n",
        "**Founding Year**: 1996\n",
        "**Headquarters**: New York City, USA\n",
        "\n",
        "### CNN\n",
        "**Political Leaning**: Left-leaning\n",
        "**Focus Areas**: US politics, breaking news, international affairs\n",
        "**Notable For**: 24-hour news cycle, analysis and commentary\n",
        "**Founding Year**: 1980\n",
        "**Headquarters**: Atlanta, USA\n",
        "\n",
        "### The New York Times\n",
        "**Political Leaning**: Left-leaning\n",
        "**Focus Areas**: US politics, international affairs, arts\n",
        "**Notable For**: In-depth reporting, investigative journalism\n",
        "**Founding Year**: 1851\n",
        "**Headquarters**: New York City, USA\n",
        "\n",
        "### The Wall Street Journal\n",
        "**Political Leaning**: Center-right (news), Right-leaning (editorial)\n",
        "**Focus Areas**: Business, finance, US politics\n",
        "**Notable For**: Financial reporting, business analysis\n",
        "**Founding Year**: 1889\n",
        "**Headquarters**: New York City, USA\n",
        "\n",
        "## Understanding Media Bias Ratings\n",
        "\n",
        "### How Media Bias Is Evaluated\n",
        "1. **Content Analysis**: Systematic examination of language, sources, and framing\n",
        "2. **Source Diversity**: Variety of perspectives included in reporting\n",
        "3. **Factual Accuracy**: Verification of claims against primary sources\n",
        "4. **Transparency**: Disclosure of methods, sources, and potential conflicts\n",
        "\n",
        "### Common Bias Classifications\n",
        "1. **Left**: Favors liberal/progressive perspectives\n",
        "2. **Lean Left**: Slight preference for liberal perspectives\n",
        "3. **Center**: Balanced coverage with minimal bias\n",
        "4. **Lean Right**: Slight preference for conservative perspectives\n",
        "5. **Right**: Favors conservative perspectives\n",
        "\n",
        "### Factors That Influence News Coverage\n",
        "1. **Ownership Structure**: Corporate vs. independent ownership\n",
        "2. **Revenue Model**: Subscription vs. advertising-based\n",
        "3. **Target Audience**: Demographics and political leanings\n",
        "4. **Editorial Policies**: Guidelines for reporting and fact-checking\n",
        "5. **Geographic Focus**: Local, national, or international emphasis\n",
        "\"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ctwe5LUyIRM7"
      },
      "outputs": [],
      "source": [
        "with open(f\"{RAG_FOLDER}/news_sources_info.md\", \"w\") as f:\n",
        "    f.write(news_sources_info)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ljr4MGvdKtK6",
        "outputId": "aad9963b-aee2-470f-bd62-bd79ec8ef57c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vector store vs_680cbf0f852481919a7d807023a02e7d ready with 2 files\n"
          ]
        }
      ],
      "source": [
        "def create_vector_store():\n",
        "    # 1. Create empty vector store\n",
        "    vector_store = client.vector_stores.create(  # NOT in beta namespace\n",
        "        name=\"News Analysis Store\",\n",
        "        chunking_strategy={\"type\": \"auto\"}\n",
        "    )\n",
        "\n",
        "    # 2. Upload files separately\n",
        "    file_paths = [\n",
        "        f\"{RAG_FOLDER}/news_analysis_guidelines.md\",\n",
        "        f\"{RAG_FOLDER}/news_sources_info.md\"\n",
        "    ]\n",
        "\n",
        "    # Upload files with assistants purpose\n",
        "    files = [client.files.create(file=open(path, \"rb\"), purpose=\"assistants\")\n",
        "            for path in file_paths]\n",
        "\n",
        "    # 3. Attach files to vector store\n",
        "    for file in files:\n",
        "        client.vector_stores.files.create(  # Direct vector_stores path\n",
        "            vector_store_id=vector_store.id,\n",
        "            file_id=file.id\n",
        "        )\n",
        "\n",
        "    print(f\"Vector store {vector_store.id} ready with {len(files)} files\")\n",
        "    return vector_store.id\n",
        "\n",
        "# Create vector store\n",
        "vector_store_id = create_vector_store()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "jYEVD2AVKtEd"
      },
      "outputs": [],
      "source": [
        "assistant = client.beta.assistants.create(\n",
        "    name=\"News Intelligence Aggregator\",\n",
        "    instructions=\"\"\"You are a sophisticated News Intelligence Aggregator assistant specialized in gathering, analyzing, and presenting news in a thoughtful and insightful manner.\n",
        "\n",
        "Your capabilities include:\n",
        "1. Fetching current news headlines and articles from various sources\n",
        "2. Analyzing news content for trends, sentiment, and patterns\n",
        "3. Providing context and background for major news stories\n",
        "4. Comparing coverage across different news sources\n",
        "5. Generating visualizations of news data\n",
        "6. Offering balanced perspectives on complex topics\n",
        "\n",
        "When analyzing news:\n",
        "- Always maintain objectivity and avoid political bias\n",
        "- Consider multiple perspectives on controversial topics\n",
        "- Verify information across multiple sources when possible\n",
        "- Distinguish between facts and opinions in your analysis\n",
        "- Provide context to help users understand the significance of news events\n",
        "- Be transparent about limitations in available information\n",
        "\n",
        "Your personality combines the analytical rigor of a seasoned journalist with the contextual understanding of a historian. You are neither sensationalist nor boring - you present information clearly while highlighting truly important developments and patterns.\n",
        "\n",
        "Use the code interpreter for data analysis, sentiment analysis, and visualization tasks. Use function calls to retrieve fresh news data. Use your knowledge files to apply best practices in news analysis and understand media sources.\"\"\",\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    tools=[\n",
        "        {\"type\": \"file_search\"},\n",
        "        {\"type\": \"code_interpreter\"},\n",
        "        {\n",
        "            \"type\": \"function\",\n",
        "            \"function\": {\n",
        "                \"name\": \"fetch_top_headlines\",\n",
        "                \"description\": \"Fetch top news headlines by country/category\",\n",
        "                \"parameters\": {\n",
        "                    \"type\": \"object\",\n",
        "                    \"properties\": {\n",
        "                        \"country\": {\"type\": \"string\"},\n",
        "                        \"category\": {\n",
        "                            \"type\": \"string\",\n",
        "                            \"enum\": [\"business\", \"entertainment\", \"general\", \"health\", \"science\", \"sports\", \"technology\"]\n",
        "                        },\n",
        "                        \"query\": {\"type\": \"string\"},\n",
        "                        \"page_size\": {\"type\": \"integer\"}\n",
        "                    },\n",
        "                    \"required\": [\"country\"]\n",
        "                }\n",
        "            }\n",
        "        },\n",
        "        {\n",
        "            \"type\": \"function\",\n",
        "            \"function\": {\n",
        "                \"name\": \"search_news\",\n",
        "                \"description\": \"Search for news articles by keywords and date range\",\n",
        "                \"parameters\": {\n",
        "                    \"type\": \"object\",\n",
        "                    \"properties\": {\n",
        "                        \"query\": {\"type\": \"string\"},\n",
        "                        \"from_date\": {\"type\": \"string\"},\n",
        "                        \"to_date\": {\"type\": \"string\"},\n",
        "                        \"sort_by\": {\n",
        "                            \"type\": \"string\",\n",
        "                            \"enum\": [\"relevancy\", \"popularity\", \"publishedAt\"]\n",
        "                        },\n",
        "                        \"page_size\": {\"type\": \"integer\"}\n",
        "                    },\n",
        "                    \"required\": [\"query\"]\n",
        "                }\n",
        "            }\n",
        "        },\n",
        "        {\n",
        "            \"type\": \"function\",\n",
        "            \"function\": {\n",
        "                \"name\": \"get_news_sources\",\n",
        "                \"description\": \"Get available news sources by country/category\",\n",
        "                \"parameters\": {\n",
        "                    \"type\": \"object\",\n",
        "                    \"properties\": {\n",
        "                        \"country\": {\"type\": \"string\"},\n",
        "                        \"category\": {\n",
        "                            \"type\": \"string\",\n",
        "                            \"enum\": [\"business\", \"entertainment\", \"general\", \"health\", \"science\", \"sports\", \"technology\"]\n",
        "                        },\n",
        "                        \"language\": {\"type\": \"string\"}\n",
        "                    }\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "    ],\n",
        "    tool_resources={\n",
        "        \"file_search\": {\n",
        "            \"vector_store_ids\": [vector_store_id]\n",
        "        }\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "8TOqetwuIVbV"
      },
      "outputs": [],
      "source": [
        "def fetch_top_headlines(country='us', category=None, query=None, page_size=10):\n",
        "    \"\"\"\n",
        "    Fetch top headlines from NewsAPI\n",
        "\n",
        "    Parameters:\n",
        "        country (str): Country code (e.g., 'us', 'gb', 'in')\n",
        "        category (str): Category (e.g., 'business', 'technology', 'sports')\n",
        "        query (str): Search query\n",
        "        page_size (int): Number of results to return\n",
        "\n",
        "    Returns:\n",
        "        dict: JSON response with headlines\n",
        "    \"\"\"\n",
        "    url = \"https://newsapi.org/v2/top-headlines\"\n",
        "\n",
        "    params = {\n",
        "        \"apiKey\": NEWS_API_KEY,\n",
        "        \"country\": country,\n",
        "        \"pageSize\": page_size\n",
        "    }\n",
        "\n",
        "    if category:\n",
        "        params[\"category\"] = category\n",
        "\n",
        "    if query:\n",
        "        params[\"q\"] = query\n",
        "\n",
        "    response = requests.get(url, params=params)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        print(f\"üåê Fetched {len(response.json()['articles'])} headlines from {country.upper()}\")\n",
        "        return response.json()\n",
        "    else:\n",
        "        return {\"error\": f\"API request failed with status code {response.status_code}: {response.text}\"}\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "0CHe5E31IZR4"
      },
      "outputs": [],
      "source": [
        "def search_news(query, from_date=None, to_date=None, sort_by='publishedAt', page_size=10):\n",
        "    \"\"\"\n",
        "    Search for news articles with NewsAPI\n",
        "\n",
        "    Parameters:\n",
        "        query (str): Search query\n",
        "        from_date (str): Start date in format YYYY-MM-DD\n",
        "        to_date (str): End date in format YYYY-MM-DD\n",
        "        sort_by (str): How to sort results ('relevancy', 'popularity', 'publishedAt')\n",
        "        page_size (int): Number of results to return\n",
        "\n",
        "    Returns:\n",
        "        dict: JSON response with news articles\n",
        "    \"\"\"\n",
        "    url = \"https://newsapi.org/v2/everything\"\n",
        "\n",
        "    # Default dates if none provided\n",
        "    if not from_date:\n",
        "        from_date = (datetime.now() - timedelta(days=7)).strftime('%Y-%m-%d')\n",
        "    if not to_date:\n",
        "        to_date = datetime.now().strftime('%Y-%m-%d')\n",
        "\n",
        "\n",
        "    print(f\"üìÜ Actual dates used: {from_date} to {to_date}\")\n",
        "\n",
        "\n",
        "    params = {\n",
        "        \"apiKey\": NEWS_API_KEY,\n",
        "        \"q\": query,\n",
        "        \"from\": from_date,\n",
        "        \"to\": to_date,\n",
        "        \"sortBy\": sort_by,\n",
        "        \"pageSize\": page_size\n",
        "    }\n",
        "\n",
        "    response = requests.get(url, params=params)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        print(f\"üîé Search results for '{query}': {len(response.json()['articles'])} articles\")\n",
        "        return response.json()\n",
        "    else:\n",
        "        return {\"error\": f\"API request failed with status code {response.status_code}: {response.text}\"}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "jZFCtTqLId_y"
      },
      "outputs": [],
      "source": [
        "def get_news_sources(country=None, category=None, language=None):\n",
        "    \"\"\"\n",
        "    Get available news sources from NewsAPI\n",
        "\n",
        "    Parameters:\n",
        "        country (str): Country code (e.g., 'us', 'gb', 'in')\n",
        "        category (str): Category (e.g., 'business', 'technology', 'sports')\n",
        "        language (str): Language code (e.g., 'en', 'fr', 'es')\n",
        "\n",
        "    Returns:\n",
        "        dict: JSON response with news sources\n",
        "    \"\"\"\n",
        "    url = \"https://newsapi.org/v2/sources\"\n",
        "\n",
        "    params = {\"apiKey\": NEWS_API_KEY}\n",
        "\n",
        "    if country:\n",
        "        params[\"country\"] = country\n",
        "\n",
        "    if category:\n",
        "        params[\"category\"] = category\n",
        "\n",
        "    if language:\n",
        "        params[\"language\"] = language\n",
        "\n",
        "    response = requests.get(url, params=params)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        return response.json()\n",
        "    else:\n",
        "        return {\"error\": f\"API request failed with status code {response.status_code}: {response.text}\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "VTz7kRaKJQwc"
      },
      "outputs": [],
      "source": [
        "tools = [\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"fetch_top_headlines\",\n",
        "            \"description\": \"Fetch top news headlines by country, category, or search query\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"country\": {\n",
        "                        \"type\": \"string\",\n",
        "                        \"description\": \"The 2-letter ISO 3166-1 code of the country (e.g., 'us', 'gb', 'in')\"\n",
        "                    },\n",
        "                    \"category\": {\n",
        "                        \"type\": \"string\",\n",
        "                        \"enum\": [\"business\", \"entertainment\", \"general\", \"health\", \"science\", \"sports\", \"technology\"],\n",
        "                        \"description\": \"The category to get headlines for\"\n",
        "                    },\n",
        "                    \"query\": {\n",
        "                        \"type\": \"string\",\n",
        "                        \"description\": \"Keywords or phrases to search for in headlines\"\n",
        "                    },\n",
        "                    \"page_size\": {\n",
        "                        \"type\": \"integer\",\n",
        "                        \"description\": \"Number of results to return (default: 10, max: 100)\"\n",
        "                    }\n",
        "                },\n",
        "                \"required\": [\"country\"]\n",
        "            }\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"search_news\",\n",
        "            \"description\": \"Search for news articles by keywords, date range, and sorting criteria\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"query\": {\n",
        "                        \"type\": \"string\",\n",
        "                        \"description\": \"Keywords or phrases to search for in articles\"\n",
        "                    },\n",
        "                    \"from_date\": {\n",
        "                        \"type\": \"string\",\n",
        "                        \"description\": \"Start date in format YYYY-MM-DD (defaults to 7 days ago)\"\n",
        "                    },\n",
        "                    \"to_date\": {\n",
        "                        \"type\": \"string\",\n",
        "                        \"description\": \"End date in format YYYY-MM-DD (defaults to today)\"\n",
        "                    },\n",
        "                    \"sort_by\": {\n",
        "                        \"type\": \"string\",\n",
        "                        \"enum\": [\"relevancy\", \"popularity\", \"publishedAt\"],\n",
        "                        \"description\": \"How to sort the articles\"\n",
        "                    },\n",
        "                    \"page_size\": {\n",
        "                        \"type\": \"integer\",\n",
        "                        \"description\": \"Number of results to return (default: 10, max: 100)\"\n",
        "                    }\n",
        "                },\n",
        "                \"required\": [\"query\"]\n",
        "            }\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"get_news_sources\",\n",
        "            \"description\": \"Get available news sources by country, category, or language\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"country\": {\n",
        "                        \"type\": \"string\",\n",
        "                        \"description\": \"The 2-letter ISO 3166-1 code of the country (e.g., 'us', 'gb', 'in')\"\n",
        "                    },\n",
        "                    \"category\": {\n",
        "                        \"type\": \"string\",\n",
        "                        \"enum\": [\"business\", \"entertainment\", \"general\", \"health\", \"science\", \"sports\", \"technology\"],\n",
        "                        \"description\": \"The category of news sources\"\n",
        "                    },\n",
        "                    \"language\": {\n",
        "                        \"type\": \"string\",\n",
        "                        \"description\": \"The 2-letter ISO 639-1 code of the language (e.g., 'en', 'fr', 'es')\"\n",
        "                    }\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "]\n",
        "\n",
        "# Step 7: Create the assistant\n",
        "# First, upload the RAG files we created\n",
        "file_ids = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "aYVMntNdJVee"
      },
      "outputs": [],
      "source": [
        "thread = client.beta.threads.create()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "Bq-YU9AtJYMx"
      },
      "outputs": [],
      "source": [
        "def process_tool_calls(run, thread_id):\n",
        "\n",
        "\n",
        "    tool_calls = run.required_action.submit_tool_outputs.tool_calls\n",
        "    tool_outputs = []\n",
        "\n",
        "    for tool_call in tool_calls:\n",
        "        function_name = tool_call.function.name\n",
        "        function_args = json.loads(tool_call.function.arguments)\n",
        "\n",
        "        print(f\"üîß Calling {function_name} with args: {function_args}\")\n",
        "\n",
        "\n",
        "        output = None\n",
        "        if function_name == \"fetch_top_headlines\":\n",
        "            output = fetch_top_headlines(**function_args)\n",
        "            if 'articles' in output:\n",
        "                print(f\"üóûÔ∏è Retrieved {len(output['articles'])} articles\")\n",
        "        elif function_name == \"search_news\":\n",
        "            output = search_news(**function_args)\n",
        "            if 'articles' in output:\n",
        "                print(f\"üîç Found {len(output['articles'])} articles for query: '{function_args['query']}'\")\n",
        "        elif function_name == \"get_news_sources\":\n",
        "            output = get_news_sources(**function_args)\n",
        "            if 'sources' in output:\n",
        "                print(f\"üì∞ Found {len(output['sources'])} sources with params: {function_args}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        tool_outputs.append({\n",
        "            \"tool_call_id\": tool_call.id,\n",
        "            \"output\": json.dumps(output)\n",
        "        })\n",
        "\n",
        "    # Submit outputs back to the assistant\n",
        "    return client.beta.threads.runs.submit_tool_outputs(\n",
        "        thread_id=thread_id,\n",
        "        run_id=run.id,\n",
        "        tool_outputs=tool_outputs\n",
        "    )\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "QcWGJBmHbQZ0"
      },
      "outputs": [],
      "source": [
        "def chat_with_assistant(user_message):\n",
        "    # Add the user's message to the thread\n",
        "    client.beta.threads.messages.create(\n",
        "        thread_id=thread.id,\n",
        "        role=\"user\",\n",
        "        content=user_message\n",
        "    )\n",
        "\n",
        "    # Create a run\n",
        "    run = client.beta.threads.runs.create(\n",
        "        thread_id=thread.id,\n",
        "        assistant_id=assistant.id\n",
        "    )\n",
        "\n",
        "    # Poll for the run to complete\n",
        "    while True:\n",
        "        run = client.beta.threads.runs.retrieve(\n",
        "            thread_id=thread.id,\n",
        "            run_id=run.id\n",
        "        )\n",
        "\n",
        "        if run.status == \"completed\":\n",
        "            print(\"Run completed\")\n",
        "            break\n",
        "        elif run.status == \"requires_action\":\n",
        "            print(\"Run requires action\")\n",
        "            run = process_tool_calls(run, thread.id)\n",
        "        elif run.status in [\"failed\", \"cancelled\", \"expired\"]:\n",
        "            print(f\"Run ended with status: {run.status}\")\n",
        "            break\n",
        "\n",
        "        time.sleep(1)\n",
        "\n",
        "    #rag_keywords = [\"media bias\", \"source profile\", \"editorial policy\"]\n",
        "    #visualization_extensions = [\".png\", \".jpg\", \".chart\"]\n",
        "\n",
        "    # Get messages (newest first)\n",
        "    messages = client.beta.threads.messages.list(\n",
        "        thread_id=thread.id\n",
        "    )\n",
        "\n",
        "    # Return the latest assistant message\n",
        "    # for message in messages.data:\n",
        "    #     if message.role == \"assistant\":\n",
        "    #         for content_block in message.content:\n",
        "    #             # Check for RAG usage\n",
        "    #             if any(keyword in content_block.text.value.lower()\n",
        "    #                    for keyword in rag_keywords):\n",
        "    #                 print(\"\\nüìö RAG Context Used: Media bias profiles\")\n",
        "\n",
        "    #             # Check for visualizations\n",
        "    #             if hasattr(content_block, 'file_id'):\n",
        "    #                 print(f\"\\nüìà Visualization Generated: {content_block.file_id}\")\n",
        "\n",
        "    #         return message.content\n",
        "\n",
        "\n",
        "    for message in messages.data:\n",
        "      if message.role == \"assistant\":\n",
        "        return message.content\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "KgSgL9rxbUhl"
      },
      "outputs": [],
      "source": [
        "def demonstrate_assistant():\n",
        "    print(\"=== News Intelligence Aggregator Demo ===\\n\")\n",
        "\n",
        "    # Example 1: Get top headlines\n",
        "    print(\"Example 1: Getting top technology headlines\")\n",
        "    response = chat_with_assistant(\"What are the top technology headlines today?\")\n",
        "    for content_block in response:\n",
        "        if hasattr(content_block, 'text'):\n",
        "            print(content_block.text.value)\n",
        "    print(\"\\n\" + \"-\"*50 + \"\\n\")\n",
        "\n",
        "    # Example 2: Analyze a specific news topic\n",
        "    print(\"Example 2: Analyzing coverage of a major news topic\")\n",
        "    response = chat_with_assistant(\"Can you analyze recent news about climate change and show me the sentiment trends?\")\n",
        "    for content_block in response:\n",
        "        if hasattr(content_block, 'text'):\n",
        "            print(content_block.text.value)\n",
        "    print(\"\\n\" + \"-\"*50 + \"\\n\")\n",
        "\n",
        "    # Example 3: Compare news sources\n",
        "    print(\"Example 3: Comparing coverage across news sources\")\n",
        "    response = chat_with_assistant(\"Compare how CNN and Fox News are covering the latest political developments.\")\n",
        "    for content_block in response:\n",
        "        if hasattr(content_block, 'text'):\n",
        "            print(content_block.text.value)\n",
        "    print(\"\\n\" + \"-\"*50 + \"\\n\")\n",
        "\n",
        "# Run the demonstration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "iiOPyUKXbb6M"
      },
      "outputs": [],
      "source": [
        "def interactive_chat():\n",
        "    print(\"Welcome to News Intelligence Aggregator!\")\n",
        "    print(\"Type 'exit' to end the conversation\\n\")\n",
        "\n",
        "    while True:\n",
        "        user_input = input(\"You: \")\n",
        "        if user_input.lower() == 'exit':\n",
        "            break\n",
        "\n",
        "        print(\"\\nThinking...\")\n",
        "        response = chat_with_assistant(user_input)\n",
        "\n",
        "        print(\"\\nNews Intelligence Aggregator:\")\n",
        "        for content_block in response:\n",
        "            if hasattr(content_block, 'text'):\n",
        "                print(content_block.text.value)\n",
        "        print(\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "GWI6EJzMbg6_"
      },
      "outputs": [],
      "source": [
        "def demo_sentiment_analysis():\n",
        "    \"\"\"Demonstrate sentiment analysis across different news sources\"\"\"\n",
        "    prompt = \"\"\"Analyze the sentiment of recent news about artificial intelligence from different sources.\n",
        "    Show me which sources are more positive or negative, and create a visualization of the sentiment differences.\"\"\"\n",
        "\n",
        "    print(\"Demonstrating sentiment analysis capability...\\n\")\n",
        "    print(f\"Query: {prompt}\\n\")\n",
        "\n",
        "    response = chat_with_assistant(prompt)\n",
        "    for content_block in response:\n",
        "        if hasattr(content_block, 'text'):\n",
        "            print(content_block.text.value)\n",
        "\n",
        "def demo_topic_tracking():\n",
        "    \"\"\"Demonstrate tracking a news topic over time\"\"\"\n",
        "    prompt = \"\"\"Track how news coverage of Ukraine has evolved over the past week.\n",
        "    Can you identify any significant shifts in focus or tone? Create a visualization showing the main subtopics.\"\"\"\n",
        "\n",
        "    print(\"Demonstrating topic tracking capability...\\n\")\n",
        "    print(f\"Query: {prompt}\\n\")\n",
        "\n",
        "    response = chat_with_assistant(prompt)\n",
        "    for content_block in response:\n",
        "        if hasattr(content_block, 'text'):\n",
        "            print(content_block.text.value)\n",
        "\n",
        "def demo_source_comparison():\n",
        "    \"\"\"Demonstrate comparing news sources\"\"\"\n",
        "    prompt = \"\"\"Find news about the economy from both left-leaning and right-leaning sources.\n",
        "    Compare their coverage and highlight the key differences in how they frame economic issues.\"\"\"\n",
        "\n",
        "    print(\"Demonstrating news source comparison...\\n\")\n",
        "    print(f\"Query: {prompt}\\n\")\n",
        "\n",
        "    response = chat_with_assistant(prompt)\n",
        "    for content_block in response:\n",
        "        if hasattr(content_block, 'text'):\n",
        "            print(content_block.text.value)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VH7xD4Zhboqu",
        "outputId": "0ab87fff-e3ab-4ee5-d07a-d87dae1f22fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Assistant ID: asst_vNh5eH9fuqTP2QpIOlYxer2u\n",
            "Thread ID: thread_YGN19pfz4qPtou2nJr9aEwxx\n",
            "RAG File IDs: []\n",
            "\n",
            "Your News Intelligence Aggregator is ready to use!\n",
            "To start using it, run the interactive_chat() function or try one of the demo functions.\n"
          ]
        }
      ],
      "source": [
        "print(f\"Assistant ID: {assistant.id}\")\n",
        "print(f\"Thread ID: {thread.id}\")\n",
        "print(\"RAG File IDs:\", file_ids)\n",
        "print(\"\\nYour News Intelligence Aggregator is ready to use!\")\n",
        "print(\"To start using it, run the interactive_chat() function or try one of the demo functions.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def log_visualization(code):\n",
        "    \"\"\"Helper to log code interpreter activities\"\"\"\n",
        "    visualization_triggers = [\n",
        "        \"plt.show()\",\n",
        "        \"sns.heatmap\",\n",
        "        \"ax.plot(\",\n",
        "        \"fig.savefig\"\n",
        "    ]\n",
        "\n",
        "    if any(trigger in code for trigger in visualization_triggers):\n",
        "        print(f\"\\nüìä Visualization Code:\\n{code}\")"
      ],
      "metadata": {
        "id": "elH6LZV3aIY0"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "2bSuXf-xbtOR",
        "outputId": "1d58de19-315c-4aaa-b9d6-cc222a8b5aa0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Welcome to News Intelligence Aggregator!\n",
            "Type 'exit' to end the conversation\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-c95830987d92>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0minteractive_chat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-20-1c6dbdca9728>\u001b[0m in \u001b[0;36minteractive_chat\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0muser_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"You: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0muser_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'exit'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1175\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m             )\n\u001b[0;32m-> 1177\u001b[0;31m         return self._input_request(\n\u001b[0m\u001b[1;32m   1178\u001b[0m             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"shell\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1219\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1220\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ],
      "source": [
        "interactive_chat()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cd_fSu1ObwSN"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}